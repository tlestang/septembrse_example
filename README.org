#+TITLE: What's the deal with Python wheels?

This walkthrough covers a fundamental aspect of Python packaging, the
wheel distribution format.

A wheel is a way of distributing a Python package.

#+begin_example
$ pip install numpy
Collecting numpy
  Downloading numpy-1.21.2-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.8 MB)
     |████████████████████████████████| 15.8 MB 65 kB/s
Installing collected packages: numpy
Successfully installed numpy-1.21.2
#+end_example

That file
~numpy-1.21.2-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl~
is a Python wheel. It contains everything needed to install NumPy 1.21
in your Python package directory. A wheel plays the role of what we
call a package in some other contexts (e.g. ~.rpm~ or ~.deb~ package
installation on GNU/Linux) but in Python parlance the word package is
already taken. In Python we talk of distribution (packages) to avoid
confusion. A wheel is a distribution - it /contains/ a Python package.

There are mainly three sections to this walktrough:
1. Building a wheel for an example package
2. The ~manylinux~ policy(ies) and how to build portable wheels.
3. Automatically building and releasing wheels on Continuous
   Integration systems.

* Example package

  The example package consists of two files:
  - A C++ extension module ~src/cpp/ddot.cpp~ named ~example~.
  - A Python file ~dot_product.py~ that imports the ~example~ extension module.

  Additionanly, the C++ extension module relies on the ~cblas_ddot~
  which comes from an external C library (a BLAS library such as
  OpenBLAS).

  Package build and installation:
  - The extension module is written using ~pybind11~ which a C++
    library that makes it easy interface Python and C++.
  - I used CMake to manage the build simply because CMake works well
    with pybind11 (and this case is well documented).
  - Overall, the Python package is built with ~scikit-build~ which is
    a extension of ~setuptools~ that makes it easy to use CMake as
    part of the setup process.

* Building a wheel distribution

  A wheel is built using ~setuptools~ with the ~wheel~ package.

  #+begin_src shell
    python setup.py bdist_wheel
  #+end_src

  Let's look at what is happening under the hood.

  1. We start with some CMake output. The C++ extension module
     ~example~ is compiled.

     #+begin_example
       -- Build files have been written to: /home/thibault/repos/septembrse_example/_skbuild/linux-x86_64-3.9/cmake-build
       [ 50%] Building CXX object CMakeFiles/example.dir/src/cpp/ddot.cpp.o
       [100%] Linking CXX shared module example.cpython-39-x86_64-linux-gnu.so
       [100%] Built target example
     #+end_example

   2. Then there is a succesion of creating temporary directories and
	copying files around. Ultimately, both the the Python source
	files and the compiled extension are copied into the ~wheel/~
	directory.

   3. The third step is writing some metadata about the package itself
      and its build. So far this is exactly what happens when you
      install a Python package. Except this time it is install into
      this temporary ~wheel/~ directory instead of your local package
      directory.

   4. The final step is taking the content of that ~wheel~ direcotry
      and putting its content into a zip archive. The ~wheel~
      directory is removed.

  What we learn from this is that a wheel distribution is a zip
  archive that contains the installed form of a Python package.
  #+begin_example
    unzip -l dist/septembrse-0.0.0-cp39-cp39-linux_x86_64.whl
    Archive:  dist/septembrse-0.0.0-cp39-cp39-linux_x86_64.whl
      Length      Date    Time    Name
    ---------  ---------- -----   ----
	   15  2021-09-04 09:02   example_pkg/__init__.py
	93400  2021-09-04 09:02   example_pkg/example.cpython-39-x86_64-linux-gnu.so
	  241  2021-09-04 09:02   septembrse-0.0.0.dist-info/METADATA
	   97  2021-09-04 09:02   septembrse-0.0.0.dist-info/WHEEL
	   12  2021-09-04 09:02   septembrse-0.0.0.dist-info/top_level.txt
	  495  2021-09-04 09:02   septembrse-0.0.0.dist-info/RECORD
    ---------                     -------
	94260                     6 files

  #+end_example

  Now when you install this wheel, all ~pip~ has to do is copy the
  files into your local package directory. It doesn't have to run the
  ~setup.py~ script - all the hard work is already done. Notice that
  the ~setup.py~ script isn't even contained inside the wheel.

  The immediate benefit of this is that I can now share my package
  with my friends, and they don't have to worry about building it.
  They don't have to worry about setuptools, scikit-build, CMake,
  OpenBLAS. They just ~pip install~ and use the package. Its also a
  smaller file to share.


  The downside is that - if my wheel contains compiled code - it is
  platform and python version specific. If its purely Python, I can
  share it with the world and don't worry about portability. If it's
  not, then I'm going to have to build the wheel for each plaftform,
  for each python version I want to support.


* manylinux

  Now let's focus on the case of GNU/Linux, for which there is an
  added complication.  On GNU/Linux, virtually every executable or
  shared library has a dynamic dependency on the GNU standard c
  library (/glibc/). This library is responsible for interfacing with
  the Linux kernel. When you run code from a compiled Python
  extension, this extension is expecting to be able to find some
  symbols (constants, functions) in glibc shared library.

  Now, newer glibc versions are not garanteed to work with older ones.
  This is a problem because different GNU/Linux distros come with the
  different versions of /glibc/. If you build your wheel the latest
  Ubuntu, it's unlikely to work on an older distribution with an older
  glibc.

  The opposite, however, is true. It is garanteed that code linked
  against an older version of glibc wilkl work with a newer one.  So
  in order to build portable wheels, that work on /manylinux/
  distributions, we want to be doing so on older systems that ship
  with older versions of glibc.

  All of this is irrelevant if your package is purely Python code.
  But if you do have one or more extension modules, you need to think
  about that.

  As a Python packager, you don't have to find and install an old
  CentOS 5 image in order to build your wheels. There is a group of
  people named the [[https://www.pypa.io/en/latest/][Python Packaging Authority]] who maintains a set of
  docker images you can use to build your wheels inside.

  We don't have to it ourselves. They're is a group of people named
  ]] that take care of maintaining
  projects used in Python packaging (e.g. PyPI). They maintain [[https://github.com/pypa/manylinux#docker-images][a set
  of Docker images]] you can use to buiold your wheels in.

  For instance the ~manylinux2014~ image is based on CentOS 7:

  #+begin_src shell
    docker run -i -t -v `pwd`:/io quay.io/pypa/manylinux2014_x86_64 /bin/bash
  #+end_src

  Manylinux images contain all currently supported Python versions:
  #+begin_src shell
    root@221b30d4d160:/# ls /opt/python
    cp310-cp310  cp36-cp36m  cp37-cp37m  cp38-cp38	cp39-cp39  pp37-pypy37_pp73
  #+end_src

  Let's build our wheel for, say, Python 3.8. First we install
  OpenBLAS (required to build the C++ extension module).
  #+begin_src shell
    apt update && apt install libopenblas-dev
  #+end_src

  We then build the wheel
  #+begin_src shell
    root@221b30d4d160:/# cd /io/
    root@221b30d4d160:/io# /opt/python/cp38-cp38/bin/pip wheel .
  #+end_src

  #+begin_src shell
    root@221b30d4d160:/io# ls -l | grep .whl$
    -rw-r--r-- 1 root root   42127 Sep  3 09:58 septembrse-0.0.0-cp38-cp38-linux_x86_64.whl
  #+end_src

  Are we good yet? Not exactly. Our wheel's platform tag is still
  ~linux_x86_64~ as opposed to something based on ~manylinux~. The
  platform tag is important because when ~pip~ goes to look for wheels
  to install, the platform tag is what is helping it choose the right
  version to download and install.

  The attribution of the ~manylinux~ platform tag is not the job of
  ~pip~, but it is ~auditwheel~'s. This utility scans the wheel and
  decides whether or not it can be attributed a ~manylinux~ tag. If
  yes, it creates a new wheel with the correct name tag.

  Let's first inspect out wheel - this only prints info, doest not
  create a new wheel yet.

  #+begin_example
    [root@e42ba33f35c4 io]# auditwheel show septembrse-0.0.0-cp38-cp38-linux_x86_64.whl

    septembrse-0.0.0-cp38-cp38-linux_x86_64.whl is consistent with the
    following platform tag: "linux_x86_64".

    The wheel references external versioned symbols in these
    system-provided shared libraries: libgcc_s.so.1 with versions
    {'GCC_3.0', 'GCC_3.3', 'GCC_4.2.0', 'GCC_4.3.0', 'GCC_3.3.1'},
    libc.so.6 with versions {'GLIBC_2.3', 'GLIBC_2.3.4', 'GLIBC_2.10',
    'GLIBC_2.14', 'GLIBC_2.4', 'GLIBC_2.2.5', 'GLIBC_2.17'},
    libstdc++.so.6 with versions {'CXXABI_1.3.3', 'GLIBCXX_3.4.18',
    'CXXABI_1.3', 'GLIBCXX_3.4', 'CXXABI_1.3.2', 'CXXABI_1.3.5'},
    libgfortran.so.3 with versions {'GFORTRAN_1.0'}, libm.so.6 with
    versions {'GLIBC_2.2.5'}, libquadmath.so.0 with versions
    {'QUADMATH_1.0'}

    This constrains the platform tag to "manylinux_2_17_x86_64". In order
    to achieve a more compatible tag, you would need to recompile a new
    wheel from source on a system with earlier versions of these
    libraries, such as a recent manylinux image.
  #+end_example

  The important information is that our wheel is valid for the
  platform tag ~manylinux_2_17_x86_64~. This means it is expected to
  work on any GNU/Linux system with a version of glibc equal or above
  2.17. That's expected because the version of glibc in this Docker
  image is 2.17.

  To actually produce the manylinux wheel, we use the  ~auditwheel repair~ command:
  #+begin_src shell
    auditwheel repair septembrse-0.0.0-cp38-cp38-linux_x86_64.whl
  #+end_src

  A new direcoty ~wheelhouse~ was created with out manylinux wheel in it.

** Runtime dependency on OpenBLAS

   There's is one detail I glossed over.

   Our C extension module has dynamics dependencies to various shared
   libraries.

   #+begin_src shell
     root@221b30d4d160:/io# ldd example_pkg/example.cpython-38-x86_64-linux-gnu.so
	     linux-vdso.so.1 (0x00007ffd2dfed000)
	     libopenblas.so.0 => /usr/lib/libopenblas.so.0 (0x00007ff591260000)
	     libstdc++.so.6 => /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007ff590ede000)
	     libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007ff590bda000)
	     libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007ff5909c3000)
	     libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007ff590624000)
	     libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007ff590407000)
	     libgfortran.so.3 => /usr/lib/x86_64-linux-gnu/libgfortran.so.3 (0x00007ff5900e1000)
	     /lib64/ld-linux-x86-64.so.2 (0x00007ff5935d1000)
	     libquadmath.so.0 => /usr/lib/x86_64-linux-gnu/libquadmath.so.0 (0x00007ff58fea2000)
   #+end_src

   Most of these dependencies are libraries that we would expect to be
   present on most GNU/Linux systems out there. But this is not the
   case of ~libopenblas~ - which we installed manually as a build-time
   dependency inside the /manylinux/ Docker image. In the current
   state of things, a user could install the wheel fine, but at the
   moment they would import the package it would break: ~libopenblas
   not found~!

   The solution to this is simple: let's add ~libopenblas~ to the
   wheel (remember, a wheel is nothing else than an archive). This is,
   however, not enough. We also need to make sure that, at runtime,
   the system knows where to look to find this shared library. This
   can be done by modyfing the ~DT_RUNPATH~ list of directories in the
   extension module shared library. This is rather technical and
   error-prone, but ~auditwheel repair~ does the work for us. Prior to
   creating the new /manylinux/ wheel, this command
   1. Scans the dynamics dependencies for the wheel's extension
      module(s)s and identifies those that are outside of a very
      restricited set of shared libraries usually distributed by most
      GNU/Linux distributions.
   2. Copies the corresponding shared libraries (~.so~ file) into the
      wheel.
   3. Modifies the ~DT_RUNPATH~ (or ~DT_RPATH~) entry for the compiled
      extension module(s) so that the dynamic linker finds these
      shares libraries at runtime.

   If use ~ldd~ on the ~example~ extension inside the manylinux wheel
   this time, we see that a few shared libraries are now found inside
   the wheel itself.

   We now have a self-contained wheel that is usable across many linux
   distributions.

   I want to point out that this runtime dependency issue isn't
   restricted to building wheels on GNU/Linux systems. On MacOS,
   [[https://github.com/matthew-brett/delocate][delocate]] does a job similar to ~auditwheel~. On Windows, I haven't
   found a way to embed dynamic dependecnies (~dll~ files) inside
   ~win32~ or ~win64~ wheels. An alternative is to link these
   dependencies statically.

* Conclusion

  That's all I wanted to show you today. If you're currently working
  on a Python project or plan to do so, then I really encourage you to
  dig a bit deeper into the topic. The material for this walthrough is
  available online, along with a list of references for further
  reading. I also encourage you distribute wheels for your projects,
  it will make it much easier to use your package. Building wheels is
  a relatively complex process for computers, but for us packagers not
  so much. That is thanks to the work of the PyPA who maintain
  manylinux and auditwheel, the contributors behing delocate and
  cibuildwheel. So let's thank them and happy wheel building!

* Pages

  - delocate
  - cibuildwheel
  - manylinux
  - framagit
